{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16dbea56-9839-4402-b9ef-b22f1912f9a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T13:49:02.176637Z",
     "iopub.status.busy": "2025-08-16T13:49:02.176256Z",
     "iopub.status.idle": "2025-08-16T13:49:02.706581Z",
     "shell.execute_reply": "2025-08-16T13:49:02.705394Z",
     "shell.execute_reply.started": "2025-08-16T13:49:02.176603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohttp==3.12.13\n",
      "boto3==1.38.39\n",
      "botocore==1.38.39\n",
      "sagemaker==2.247.0\n",
      "litellm==1.72.2\n",
      "strands-agents==0.1.6\n",
      "strands-agents-builder==0.1.2\n",
      "strands-agents-tools==0.1.4\n",
      "matplotlib==3.10.3\n",
      "pandas==2.3.0\n",
      "seaborn==0.13.2\n",
      "joblib==1.5.1\n",
      "requests==2.32.4\n",
      "uv==0.7.13"
     ]
    }
   ],
   "source": [
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7ef95d8-5db5-4a31-94bf-4bcb42423bda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T13:49:02.709127Z",
     "iopub.status.busy": "2025-08-16T13:49:02.708485Z",
     "iopub.status.idle": "2025-08-16T13:49:02.730634Z",
     "shell.execute_reply": "2025-08-16T13:49:02.721019Z",
     "shell.execute_reply.started": "2025-08-16T13:49:02.709088Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c50c54e-62fd-4c9f-85fb-0246ce8a39ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T13:49:04.067803Z",
     "iopub.status.busy": "2025-08-16T13:49:04.067109Z",
     "iopub.status.idle": "2025-08-16T13:49:12.132040Z",
     "shell.execute_reply": "2025-08-16T13:49:12.130598Z",
     "shell.execute_reply.started": "2025-08-16T13:49:04.067775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping autogluon-multimodal as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping autogluon-timeseries as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping autogluon-features as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping autogluon-common as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping autogluon-core as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.21.1 requires botocore<1.37.2,>=1.37.0, but you have botocore 1.38.39 which is incompatible.\n",
      "sagemaker-studio-analytics-extension 0.2.0 requires sparkmagic==0.22.0, but you have sparkmagic 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Warnings are safe to ignore\n",
    "%pip uninstall -q -y autogluon-multimodal autogluon-timeseries autogluon-features autogluon-common autogluon-core\n",
    "%pip install -r requirements.txt -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b7e8f71-fc23-451f-93f2-b1bbd920f30b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T13:49:12.943365Z",
     "iopub.status.busy": "2025-08-16T13:49:12.940574Z",
     "iopub.status.idle": "2025-08-16T13:49:14.828439Z",
     "shell.execute_reply": "2025-08-16T13:49:14.827463Z",
     "shell.execute_reply.started": "2025-08-16T13:49:12.943320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q boto3 python-docx PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0211748-0a2c-436a-93ff-8227fb2b575e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T13:49:15.293718Z",
     "iopub.status.busy": "2025-08-16T13:49:15.293083Z",
     "iopub.status.idle": "2025-08-16T13:49:15.299151Z",
     "shell.execute_reply": "2025-08-16T13:49:15.298405Z",
     "shell.execute_reply.started": "2025-08-16T13:49:15.293685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1699afe5-6a3b-46f8-830a-3077f791bb89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T13:49:20.485159Z",
     "iopub.status.busy": "2025-08-16T13:49:20.484814Z",
     "iopub.status.idle": "2025-08-16T13:49:24.422544Z",
     "shell.execute_reply": "2025-08-16T13:49:24.421569Z",
     "shell.execute_reply.started": "2025-08-16T13:49:20.485132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.12/site-packages (1.38.39)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.40.11-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore<1.41.0,>=1.40.11 (from boto3)\n",
      "  Using cached botocore-1.40.11-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/conda/lib/python3.12/site-packages (from boto3) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.11->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.11->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.11->boto3) (1.17.0)\n",
      "Using cached boto3-1.40.11-py3-none-any.whl (140 kB)\n",
      "Using cached botocore-1.40.11-py3-none-any.whl (14.0 MB)\n",
      "Installing collected packages: botocore, boto3\n",
      "\u001b[2K  Attempting uninstall: botocore\n",
      "\u001b[2K    Found existing installation: botocore 1.38.39\n",
      "\u001b[2K    Uninstalling botocore-1.38.39:\n",
      "\u001b[2K      Successfully uninstalled botocore-1.38.39\n",
      "\u001b[2K  Attempting uninstall: boto3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [botocore]\n",
      "\u001b[2K    Found existing installation: boto3 1.38.39m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [boto3]\n",
      "\u001b[2K    Uninstalling boto3-1.38.39:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [boto3]\n",
      "\u001b[2K      Successfully uninstalled boto3-1.38.39━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [boto3]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [boto3]/2\u001b[0m [boto3]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.21.1 requires botocore<1.37.2,>=1.37.0, but you have botocore 1.40.11 which is incompatible.\n",
      "sagemaker-studio-analytics-extension 0.2.0 requires sparkmagic==0.22.0, but you have sparkmagic 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.40.11 botocore-1.40.11\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bd665cc-9725-49ce-9a54-82fd0be7bc82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T21:24:02.807842Z",
     "iopub.status.busy": "2025-08-17T21:24:02.805750Z",
     "iopub.status.idle": "2025-08-17T21:24:02.814378Z",
     "shell.execute_reply": "2025-08-17T21:24:02.813425Z",
     "shell.execute_reply.started": "2025-08-17T21:24:02.807764Z"
    }
   },
   "outputs": [],
   "source": [
    "#from utils.strands_sagemaker import SageMakerAIModel\n",
    "from strands.models.bedrock import BedrockModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29eda0fd-80db-4b75-8dd6-a425b83f45a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T21:24:02.965004Z",
     "iopub.status.busy": "2025-08-17T21:24:02.964621Z",
     "iopub.status.idle": "2025-08-17T21:24:02.970437Z",
     "shell.execute_reply": "2025-08-17T21:24:02.969584Z",
     "shell.execute_reply.started": "2025-08-17T21:24:02.964968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "from strands import Agent, tool\n",
    "from strands_tools import http_request \n",
    "import json, time, uuid, re, requests\n",
    "import io\n",
    "import mimetypes\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "try:\n",
    "    import boto3\n",
    "    from botocore.exceptions import BotoCoreError, ClientError\n",
    "except Exception:\n",
    "    boto3 = None\n",
    "\n",
    "try:\n",
    "    from PyPDF2 import PdfReader\n",
    "except Exception:\n",
    "    PdfReader = None\n",
    "\n",
    "try:\n",
    "    import docx  # python-docx\n",
    "except Exception:\n",
    "    docx = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "873637a3-86b2-45ae-8590-41cba08dd67b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T21:42:35.909135Z",
     "iopub.status.busy": "2025-08-17T21:42:35.908865Z",
     "iopub.status.idle": "2025-08-17T21:42:35.924430Z",
     "shell.execute_reply": "2025-08-17T21:42:35.923669Z",
     "shell.execute_reply.started": "2025-08-17T21:42:35.909115Z"
    }
   },
   "outputs": [],
   "source": [
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=boto3.Session().region_name\n",
    ")\n",
    "\n",
    "def invoke_model(model_id, model_input):\n",
    "    body = json.dumps(model_input)\n",
    "    \n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=body\n",
    "    )\n",
    "    \n",
    "    response_body = json.loads(response['body'].read())\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29d1b7a1-a6e9-4e0e-bcf9-e15c5782f8a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T21:43:21.397489Z",
     "iopub.status.busy": "2025-08-17T21:43:21.396875Z",
     "iopub.status.idle": "2025-08-17T21:43:21.465389Z",
     "shell.execute_reply": "2025-08-17T21:43:21.464644Z",
     "shell.execute_reply.started": "2025-08-17T21:43:21.397462Z"
    }
   },
   "outputs": [],
   "source": [
    "provider = \"BEDROCK_Mistral\"  # Change this to SAGEMAKER to use a deployed endpoint instead of Bedrock\n",
    "provider_model_id = \"\"\n",
    "\n",
    "match provider:\n",
    "    case \"BEDROCK_Mistral\":\n",
    "        # Using Mistral 7B Instruct from Bedrock\n",
    "        full_model = BedrockModel(\n",
    "            model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
    "            max_tokens=1024,\n",
    "            temperature=0.8,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "        )\n",
    "        provider_model_id = \"mistral.mistral-7b-instruct-v0:2\"\n",
    "\n",
    "    case \"BEDROCK_Anthropic\":\n",
    "        # Using Claude 3.5 Sonnet from Bedrock\n",
    "        full_model = BedrockModel(\n",
    "            model_id=\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "            max_tokens=1024,\n",
    "            temperature=0.8,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "        )\n",
    "        provider_model_id = \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "\n",
    "    case \"SAGEMAKER\":\n",
    "        model = SageMakerAIModel({\n",
    "            \"endpoint_name\": SAGEMAKER_ENDPOINT_NAME,\n",
    "            \"max_tokens\": 16*1024,\n",
    "            \"temperature\": 0.1,\n",
    "            \"stream\": False\n",
    "\t\t})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779af3d-2a2f-451d-83f0-0ab1d185f12b",
   "metadata": {},
   "source": [
    "# Analyzer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29e48007-98c3-4b2e-85fe-6a067b2fac06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T21:43:23.363968Z",
     "iopub.status.busy": "2025-08-17T21:43:23.363689Z",
     "iopub.status.idle": "2025-08-17T21:43:23.400394Z",
     "shell.execute_reply": "2025-08-17T21:43:23.399553Z",
     "shell.execute_reply.started": "2025-08-17T21:43:23.363947Z"
    }
   },
   "outputs": [],
   "source": [
    "# ================== Analyzer (multi-source, multi-file, model-swappable) ==================\n",
    "from strands import Agent, tool\n",
    "import json, os, time, uuid, re, requests, io, mimetypes\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "# --- optional deps for S3/PDF/DOCX ---\n",
    "import boto3\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "\n",
    "# ---- environment time ----\n",
    "os.environ[\"TZ\"] = \"America/New_York\"\n",
    "if hasattr(time, \"tzset\"):\n",
    "    time.tzset()\n",
    "\n",
    "# ---- defaults / paths ----\n",
    "DEFAULT_SOURCE  = None                       # used if you call fetch_data() without data_source\n",
    "ROW_DELIM       = \"@\"\n",
    "\n",
    "DATA_LOG_FILE   = \"analyzer_raw_s3_data_log.txt\"\n",
    "OUTPUT_JSONL    = \"analyzer_s3_outputs.jsonl\"\n",
    "OUTPUT_DIR_INDIVIDUAL = \"analyzer_individual_mistral_outputs\"  # per-patient per-model JSON files\n",
    "\n",
    "# ===== helpers =====\n",
    "def _format_rows_as_lines(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    If the data uses '@' as a row delimiter, split onto newlines.\n",
    "    Otherwise, return the text as-is (e.g., clinician notes).\n",
    "    \"\"\"\n",
    "    text = (raw_text or \"\").strip()\n",
    "    if ROW_DELIM in text:\n",
    "        chunks = [c.strip() for c in text.split(ROW_DELIM) if c.strip()]\n",
    "        return \"\\n\".join(chunks)\n",
    "    return text\n",
    "\n",
    "def _save_formatted_to_file(formatted_text: str, log_path: str):\n",
    "    os.makedirs(os.path.dirname(log_path) or \".\", exist_ok=True)\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"\\n=== Run at {timestamp} ===\\n\")\n",
    "        f.write(formatted_text + \"\\n\")\n",
    "\n",
    "def _coerce_json(text: str):\n",
    "    \"\"\"\n",
    "    Extract the first JSON object from an LLM response and parse it.\n",
    "    \"\"\"\n",
    "    s = str(text).strip()\n",
    "    if s.startswith(\"{\") and s.endswith(\"}\"):\n",
    "        return json.loads(s)\n",
    "    m = re.search(r\"\\{.*\\}\", s, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"No JSON object found in agent output.\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "def _append_jsonl(path: str, obj: dict):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# ===== S3 helpers =====\n",
    "def _parse_s3_uri(uri: str) -> Tuple[str, str]:\n",
    "    # s3://bucket/key -> (bucket, key)\n",
    "    assert uri.lower().startswith(\"s3://\"), \"Not an s3:// URI\"\n",
    "    without = uri[5:]\n",
    "    parts = without.split(\"/\", 1)\n",
    "    bucket = parts[0]\n",
    "    key = parts[1] if len(parts) > 1 else \"\"\n",
    "    return bucket, key\n",
    "\n",
    "def _read_s3_object(uri: str) -> bytes:\n",
    "    bucket, key = _parse_s3_uri(uri)\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "        return obj[\"Body\"].read()\n",
    "    except (BotoCoreError, ClientError) as e:\n",
    "        raise RuntimeError(f\"S3 read failed for {uri}: {e}\")\n",
    "\n",
    "def _list_s3_uris(s3_prefix: str, extensions: Optional[List[str]] = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Expand an s3 prefix (ending with '/'): s3://bucket/prefix/ -> [s3://bucket/prefix/file1, ...]\n",
    "    Optionally filter by extensions ['.docx', '.pdf', '.txt'] (case-insensitive).\n",
    "    \"\"\"\n",
    "    bucket, prefix = _parse_s3_uri(s3_prefix)\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    uris = []\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            key = obj[\"Key\"]\n",
    "            if key.endswith(\"/\"):\n",
    "                continue\n",
    "            if extensions:\n",
    "                ext = os.path.splitext(key)[1].lower()\n",
    "                if ext not in [e.lower() for e in extensions]:\n",
    "                    continue\n",
    "            uris.append(f\"s3://{bucket}/{key}\")\n",
    "    return uris\n",
    "\n",
    "def _ext_or_mime(uri: str, content_bytes: bytes) -> str:\n",
    "    mime, _ = mimetypes.guess_type(uri)\n",
    "    return mime or \"application/octet-stream\"\n",
    "\n",
    "def _extract_text_from_bytes(uri: str, content: bytes) -> str:\n",
    "    mime = _ext_or_mime(uri, content)\n",
    "    luri = uri.lower()\n",
    "    if luri.endswith(\".pdf\") or mime == \"application/pdf\":\n",
    "        reader = PdfReader(io.BytesIO(content))\n",
    "        parts = []\n",
    "        for page in reader.pages:\n",
    "            try:\n",
    "                parts.append(page.extract_text() or \"\")\n",
    "            except Exception:\n",
    "                continue\n",
    "        return \"\\n\".join(p.strip() for p in parts if p)\n",
    "    if luri.endswith(\".docx\") or mime == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
    "        d = Document(io.BytesIO(content))\n",
    "        return \"\\n\".join(p.text for p in d.paragraphs if p.text)\n",
    "    # Fallback: treat as UTF-8 text\n",
    "    try:\n",
    "        return content.decode(\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        return content.decode(\"latin-1\", errors=\"ignore\")\n",
    "\n",
    "# ===== unified fetch tool (accepts data_source param) =====\n",
    "@tool\n",
    "def fetch_data(data_source: str | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch data from data_source (http/https URL, local file, or s3://bucket/key PDF/DOCX/TXT).\n",
    "    If data_source is None, uses DEFAULT_SOURCE.\n",
    "    Returns { raw_text, formatted_text, meta }.\n",
    "    \"\"\"\n",
    "    ds = data_source or DEFAULT_SOURCE\n",
    "    if not ds:\n",
    "        return {\"error\": \"No data_source provided.\", \"raw_text\": \"\", \"formatted_text\": \"\", \"meta\": {\"source_type\": \"unknown\", \"data_source\": str(ds)}}\n",
    "\n",
    "    # S3\n",
    "    if isinstance(ds, str) and ds.lower().startswith(\"s3://\"):\n",
    "        try:\n",
    "            blob = _read_s3_object(ds)\n",
    "            raw_text = _extract_text_from_bytes(ds, blob)\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"S3 error: {e}\", \"raw_text\": \"\", \"formatted_text\": \"\", \"meta\": {\"source_type\": \"s3\", \"data_source\": ds}}\n",
    "        formatted = _format_rows_as_lines(raw_text)\n",
    "        _save_formatted_to_file(formatted, DATA_LOG_FILE)\n",
    "        return {\"raw_text\": raw_text, \"formatted_text\": formatted, \"meta\": {\"source_type\": \"s3\", \"data_source\": ds}}\n",
    "\n",
    "    # URL\n",
    "    if isinstance(ds, str) and ds.lower().startswith((\"http://\", \"https://\")):\n",
    "        try:\n",
    "            resp = requests.post(ds, data={}, timeout=60)\n",
    "            resp.raise_for_status()\n",
    "            raw = resp.text\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"HTTP error: {e}\", \"raw_text\": \"\", \"formatted_text\": \"\", \"meta\": {\"source_type\": \"url\", \"data_source\": ds}}\n",
    "        formatted = _format_rows_as_lines(raw)\n",
    "        _save_formatted_to_file(formatted, DATA_LOG_FILE)\n",
    "        return {\"raw_text\": raw, \"formatted_text\": formatted, \"meta\": {\"source_type\": \"url\", \"data_source\": ds}}\n",
    "\n",
    "    # Local file\n",
    "    if isinstance(ds, str) and os.path.exists(ds):\n",
    "        try:\n",
    "            if ds.lower().endswith((\".pdf\", \".docx\")):\n",
    "                with open(ds, \"rb\") as f:\n",
    "                    content = f.read()\n",
    "                raw_text = _extract_text_from_bytes(ds, content)\n",
    "            else:\n",
    "                with open(ds, \"r\", encoding=\"utf-8\") as f:\n",
    "                    raw_text = f.read()\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"File read error: {e}\", \"raw_text\": \"\", \"formatted_text\": \"\", \"meta\": {\"source_type\": \"file\", \"data_source\": ds}}\n",
    "        formatted = _format_rows_as_lines(raw_text)\n",
    "        return {\"raw_text\": raw_text, \"formatted_text\": formatted, \"meta\": {\"source_type\": \"file\", \"data_source\": ds}}\n",
    "\n",
    "    # Unknown\n",
    "    return {\"error\": f\"Unsupported data_source: {ds}\", \"raw_text\": \"\", \"formatted_text\": \"\", \"meta\": {\"source_type\": \"unknown\", \"data_source\": str(ds)}}\n",
    "\n",
    "# ===== analyzer prompt (says to call fetch_data with the provided data_source) =====\n",
    "ANALYZER_PROMPT = \"\"\"\n",
    "You are an Analyzer Agent.\n",
    "\n",
    "Tool available:\n",
    "- fetch_data(data_source) -> {raw_text, formatted_text, meta}\n",
    "\n",
    "You will receive an input JSON with a key \"data_source\".\n",
    "INSTRUCTIONS:\n",
    "1) Call fetch_data EXACTLY ONCE with the provided data_source.\n",
    "2) Use \"formatted_text\" as your working input. It is newline-separated if the source used '@' row delimiters; otherwise it may be free text/paragraphs.\n",
    "3) Perform the analysis according to the TASK below.\n",
    "4) Produce output that matches the OUTPUT CONTRACT below EXACTLY (keys and structure). Output ONLY that JSON object and nothing else.\n",
    "5) Do not call any other tools. Do not print anything except the final JSON. Do not retry fetch_data.\n",
    "\n",
    "DEFAULT TASK:\n",
    "- Derive from the following content SMART goals that are specific, measurable, actionable, relevant and time-bounded based on the provided content.\n",
    "- Example: The SMART goal is to keep h1ac below 6.0 in the next 3 months. Monitor fasting glucose daily for 90 days and calculate the average of the daily fasting glucose readings. This is a SMART goal because it is specific to h1ac evaluation, it measures glucose daily reading and it require the action to monitor the reading daily. The glucose reading is relevant to h1ac because h1ac is the 90 day average of the glucose reading. And it is time bounded for carrying out the measurement for 90 days.\n",
    "\n",
    "DEFAULT OUTPUT CONTRACT:\n",
    "{\n",
    "  \"smart_goals\": [\n",
    "    {\n",
    "      \"goal_number\": \"integer (starts at 1 and increments for each goal)\",\n",
    "      \"description\": \"string (time-bound, measurable details)\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# ---------- helpers for filenames ----------\n",
    "def _basename_no_ext(path_or_uri: str) -> str:\n",
    "    \"\"\"\n",
    "    's3://bucket/path/patient1_summary.docx' -> 'patient1_summary'\n",
    "    'patient2.pdf' -> 'patient2'\n",
    "    'https://.../file.txt?x=y' -> 'file' (best effort)\n",
    "    \"\"\"\n",
    "    s = path_or_uri.split(\"?\", 1)[0]\n",
    "    if s.lower().startswith(\"s3://\"):\n",
    "        _, key = s[5:].split(\"/\", 1)\n",
    "        base = os.path.basename(key)\n",
    "    else:\n",
    "        base = os.path.basename(s)\n",
    "    name, _ext = os.path.splitext(base)\n",
    "    return name or \"unknown_source\"\n",
    "\n",
    "def _safe_fragment(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Make a safe filename fragment: replace non [A-Za-z0-9_-] with '_'.\n",
    "    Also replace ':', '.', '/' commonly found in model ids.\n",
    "    \"\"\"\n",
    "    s = s.replace(\":\", \"_\").replace(\"/\", \"_\").replace(\".\", \"_\")\n",
    "    return \"\".join(c if c.isalnum() or c in (\"-\", \"_\") else \"_\" for c in s)\n",
    "\n",
    "\n",
    "# ---------- batch runner ----------\n",
    "def run_analyzer_batch(\n",
    "    data_sources: list[str],\n",
    "    model_name,                              # string alias/id OR model object\n",
    "    output_jsonl: str = \"analyzer_s3_outputs.jsonl\",\n",
    "    save_each: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    For each source in data_sources:\n",
    "      - Build an Analyzer agent for the chosen model\n",
    "      - Call fetch_data(data_source=source)\n",
    "      - Append one line to the JSONL with {run_id, timestamp, data_source, model_id, analyzer_output}\n",
    "      - Write a per-patient, per-model JSON file in analyzer_individual_outputs/\n",
    "    Also expands any S3 prefix that ends with '/' into all files under that prefix.\n",
    "    \"\"\"\n",
    "    # Normalize to a plain string id (prevents JSON serialization errors)\n",
    "    model_id = provider_model_id\n",
    "\n",
    "    # Expand any s3 prefixes into object URIs\n",
    "    expanded_sources: list[str] = []\n",
    "    for src in data_sources:\n",
    "        if isinstance(src, str) and src.lower().startswith(\"s3://\") and src.endswith(\"/\"):\n",
    "            # expand directory-like prefix\n",
    "            expanded_sources.extend(_list_s3_uris(src, extensions=[\".docx\", \".pdf\", \".txt\"]))\n",
    "        else:\n",
    "            expanded_sources.append(src)\n",
    "\n",
    "    # Prepare output dir for per-patient files\n",
    "    os.makedirs(OUTPUT_DIR_INDIVIDUAL, exist_ok=True)\n",
    "\n",
    "    results: list[dict] = []\n",
    "    for src in expanded_sources:\n",
    "        # Build an Analyzer agent for this model id\n",
    "        analyzer = Agent(\n",
    "            model=model_id,\n",
    "            system_prompt=ANALYZER_PROMPT,\n",
    "            tools=[fetch_data],\n",
    "        )\n",
    "\n",
    "        # Agent input: tell it which data_source to fetch\n",
    "        payload = {\"data_source\": src}\n",
    "        raw = analyzer(json.dumps(payload))\n",
    "\n",
    "        # Parse the agent's strict-JSON output (smart_goals)\n",
    "        parsed = _coerce_json(raw)\n",
    "\n",
    "        # Append a JSONL record\n",
    "        record = {\n",
    "            \"run_id\": str(uuid.uuid4()),\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "            \"data_source\": src,\n",
    "            \"model_id\": model_id,\n",
    "            \"analyzer_output\": parsed,\n",
    "        }\n",
    "        if save_each:\n",
    "            _append_jsonl(output_jsonl, record)\n",
    "\n",
    "        # Write per-patient, per-model JSON file\n",
    "        base = _basename_no_ext(src)\n",
    "        safe_model = _safe_fragment(model_id)\n",
    "        out_path = os.path.join(\n",
    "            OUTPUT_DIR_INDIVIDUAL,\n",
    "            f\"{base}_{safe_model}_output.json\"\n",
    "        )\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(\n",
    "                {\n",
    "                    \"model_id\": model_id,\n",
    "                    \"data_source\": src,\n",
    "                    \"timestamp\": record[\"timestamp\"],\n",
    "                    \"smart_goals\": parsed.get(\"smart_goals\", []),\n",
    "                },\n",
    "                f,\n",
    "                ensure_ascii=False,\n",
    "                indent=2,\n",
    "            )\n",
    "\n",
    "        results.append(record)\n",
    "\n",
    "    return {\"count\": len(results), \"runs\": results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a4775a5-f505-4404-a56c-c84f0cabd34e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T21:43:28.254672Z",
     "iopub.status.busy": "2025-08-17T21:43:28.254279Z",
     "iopub.status.idle": "2025-08-17T21:43:28.879237Z",
     "shell.execute_reply": "2025-08-17T21:43:28.877278Z",
     "shell.execute_reply.started": "2025-08-17T21:43:28.254623Z"
    }
   },
   "outputs": [
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the ConverseStream operation: This model doesn't support system messages. Try again without a system message or use a model that supports system messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m sources \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://patient-summary-bucket/patient1_summary.docx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://patient-summary-bucket/patient2_summary.docx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://patient-summary-bucket/patient5_summary.docx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Run output behavior (JSONL + per-patient files)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mrun_analyzer_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_jsonl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_JSONL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_each\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print(json.dumps(summary, indent=2))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 276\u001b[0m, in \u001b[0;36mrun_analyzer_batch\u001b[0;34m(data_sources, model_name, output_jsonl, save_each)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Agent input: tell it which data_source to fetch\u001b[39;00m\n\u001b[1;32m    275\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_source\u001b[39m\u001b[38;5;124m\"\u001b[39m: src}\n\u001b[0;32m--> 276\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# Parse the agent's strict-JSON output (smart_goals)\u001b[39;00m\n\u001b[1;32m    279\u001b[0m parsed \u001b[38;5;241m=\u001b[39m _coerce_json(raw)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/strands/agent/agent.py:335\u001b[0m, in \u001b[0;36mAgent.__call__\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_agent_trace_span(prompt)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;66;03m# Run the event loop and get the result\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_agent_trace_span(response\u001b[38;5;241m=\u001b[39mresult)\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/strands/agent/agent.py:439\u001b[0m, in \u001b[0;36mAgent._run_loop\u001b[0;34m(self, prompt, kwargs, supplementary_callback_handler)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend(new_message)\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# Execute the event loop cycle with retry logic for context limits\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_event_loop_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43minvocation_callback_handler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversation_manager\u001b[38;5;241m.\u001b[39mapply_management(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/strands/agent/agent.py:467\u001b[0m, in \u001b[0;36mAgent._execute_event_loop_cycle\u001b[0;34m(self, callback_handler, kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# Remove agent to avoid conflicts\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Execute the main event loop cycle\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     stop_reason, message, metrics, state \u001b[38;5;241m=\u001b[39m \u001b[43mevent_loop_cycle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# will be modified by event_loop_cycle\u001b[39;49;00m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_handler_override\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_execution_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_execution_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevent_loop_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_loop_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevent_loop_parent_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AgentResult(stop_reason, message, metrics, state)\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ContextWindowOverflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;66;03m# Try reducing the context size and retrying\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/strands/event_loop/event_loop.py:190\u001b[0m, in \u001b[0;36mevent_loop_cycle\u001b[0;34m(model, system_prompt, messages, tool_config, callback_handler, tool_handler, tool_execution_handler, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_invoke_span:\n\u001b[1;32m    189\u001b[0m             tracer\u001b[38;5;241m.\u001b[39mend_span_with_error(model_invoke_span, \u001b[38;5;28mstr\u001b[39m(e), e)\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# Add message in trace and mark the end of the stream messages trace\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     stream_trace\u001b[38;5;241m.\u001b[39madd_message(message)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/strands/event_loop/event_loop.py:148\u001b[0m, in \u001b[0;36mevent_loop_cycle\u001b[0;34m(model, system_prompt, messages, tool_config, callback_handler, tool_handler, tool_execution_handler, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m model_invoke_span \u001b[38;5;241m=\u001b[39m tracer\u001b[38;5;241m.\u001b[39mstart_model_invoke_span(\n\u001b[1;32m    142\u001b[0m     parent_span\u001b[38;5;241m=\u001b[39mcycle_span,\n\u001b[1;32m    143\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    144\u001b[0m     model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     stop_reason, message, usage, metrics, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_state\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mstream_messages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_invoke_span:\n\u001b[1;32m    157\u001b[0m         tracer\u001b[38;5;241m.\u001b[39mend_model_invoke_span(model_invoke_span, message, usage)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/strands/event_loop/streaming.py:340\u001b[0m, in \u001b[0;36mstream_messages\u001b[0;34m(model, system_prompt, messages, tool_config, callback_handler, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m tool_specs \u001b[38;5;241m=\u001b[39m [tool[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoolSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tool_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m tool_config \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    339\u001b[0m chunks \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconverse(messages, tool_specs, system_prompt)\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_handler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/strands/event_loop/streaming.py:290\u001b[0m, in \u001b[0;36mprocess_stream\u001b[0;34m(chunks, callback_handler, messages, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m metrics: Metrics \u001b[38;5;241m=\u001b[39m Metrics(latencyMs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    288\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_state\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m--> 290\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Callback handler call here allows each event to be visible to the caller\u001b[39;49;00m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessageStart\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/strands/types/models/model.py:115\u001b[0m, in \u001b[0;36mModel.converse\u001b[0;34m(self, messages, tool_specs, system_prompt)\u001b[0m\n\u001b[1;32m    112\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(request)\n\u001b[1;32m    114\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot response from model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinished streaming response from model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/strands/models/bedrock.py:369\u001b[0m, in \u001b[0;36mBedrockModel.stream\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContextWindowOverflowException(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# Otherwise raise the error\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/strands/models/bedrock.py:330\u001b[0m, in \u001b[0;36mBedrockModel.stream\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m streaming:\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;66;03m# Streaming implementation\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverse_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    333\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m chunk\n\u001b[1;32m    334\u001b[0m                 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    335\u001b[0m                 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguardrail\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    336\u001b[0m             ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/botocore/client.py:602\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m     )\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/botocore/context.py:123\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[1;32m    122\u001b[0m     hook()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/botocore/client.py:1078\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m request_context\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1075\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code_override\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1076\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1077\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1078\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mValidationException\u001b[0m: An error occurred (ValidationException) when calling the ConverseStream operation: This model doesn't support system messages. Try again without a system message or use a model that supports system messages."
     ]
    }
   ],
   "source": [
    "sources = [\n",
    "    \"s3://patient-summary-bucket/patient1_summary.docx\",\n",
    "    \"s3://patient-summary-bucket/patient2_summary.docx\",\n",
    "    \"s3://patient-summary-bucket/patient3_summary.docx\",\n",
    "    \"s3://patient-summary-bucket/patient4_summary.docx\",\n",
    "    \"s3://patient-summary-bucket/patient5_summary.docx\",\n",
    "]\n",
    "\n",
    "# Run output behavior (JSONL + per-patient files)\n",
    "summary = run_analyzer_batch(\n",
    "        sources,\n",
    "        model_name=full_model,\n",
    "        output_jsonl=OUTPUT_JSONL,\n",
    "        save_each=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd3555-d92b-4105-b1af-7b07b1986994",
   "metadata": {},
   "source": [
    "# Evaluator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa82fe-585b-4274-baee-869cc67a8701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ================== Evaluator (llm as judge) ==================\n",
    "\n",
    "from strands import Agent, tool\n",
    "import json, os, time, uuid, re\n",
    "from statistics import mean\n",
    "\n",
    "# ---------- Paths ----------\n",
    "ANALYZER_JSONL = \"analyzer_s3_outputs.jsonl\"     # produced by the Analyzer\n",
    "CLINICIAN_JSON = \"clinician_evaluation.json\"  # optional: only used for engagement eval\n",
    "EVAL_JSONL     = \"evaluator_runs.jsonl\"\n",
    "\n",
    "OUTPUT_DIR_INDIVIDUAL = \"analyzer_individual_outputs\"  # per-patient per-model JSON files\n",
    "\n",
    "# ---------- File helpers ----------\n",
    "def _read_jsonl(path: str):\n",
    "    items = []\n",
    "    if not os.path.exists(path):\n",
    "        return items\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                items.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return items\n",
    "\n",
    "def _read_json(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def _append_jsonl(path: str, obj: dict):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def _coerce_json(text: str):\n",
    "    s = str(text).strip()\n",
    "    if s.startswith(\"{\") and s.endswith(\"}\"):\n",
    "        return json.loads(s)\n",
    "    m = re.search(r\"\\{.*\\}\", s, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"No JSON object found in evaluator output.\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "# ---------- Low-level loaders as tools ----------\n",
    "@tool\n",
    "def load_analyzer_runs(limit: int | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Load analyzer outputs (JSONL), sorted by timestamp ASC. Optionally keep only latest 'limit'.\n",
    "    \"\"\"\n",
    "    runs = _read_jsonl(ANALYZER_JSONL)\n",
    "    runs.sort(key=lambda r: r.get(\"timestamp\", \"\"))\n",
    "    if limit:\n",
    "        runs = runs[-limit:]\n",
    "    return {\"runs\": runs}\n",
    "\n",
    "@tool\n",
    "def load_clinician_eval() -> dict:\n",
    "    \"\"\"\n",
    "    Load clinician_evaluation.json (array), sorted by timestamp ASC (optional for SMART).\n",
    "    \"\"\"\n",
    "    items = _read_json(CLINICIAN_JSON)\n",
    "    items.sort(key=lambda r: r.get(\"timestamp\", \"\"))\n",
    "    return {\"items\": items}\n",
    "\n",
    "# ---------- Build Engagement pairs: analyzer vs clinician ----------\n",
    "def _build_engagement_cases(runs, clinician_items):\n",
    "    # index clinician by timestamp -> {device_id -> rec}\n",
    "    clin_index = {}\n",
    "    for row in clinician_items:\n",
    "        ts = row.get(\"timestamp\", \"\")\n",
    "        for rec in row.get(\"clinician_output\", {}).get(\"recommendations\", []):\n",
    "            clin_index.setdefault(ts, {})[rec.get(\"device_id\")] = {\n",
    "                \"category_recommended\": rec.get(\"category_recommended\"),\n",
    "                \"rationale\": rec.get(\"rationale\"),\n",
    "            }\n",
    "\n",
    "    cases = []\n",
    "    for run in runs:\n",
    "        ts = run.get(\"timestamp\", \"\")\n",
    "        recs = (run.get(\"analyzer_output\") or {}).get(\"recommendations\", [])\n",
    "        for rec in recs:\n",
    "            dev = rec.get(\"device_id\")\n",
    "            analyzer_rec = {\n",
    "                \"category_recommended\": rec.get(\"category_recommended\"),\n",
    "                \"rationale\": rec.get(\"rationale\"),\n",
    "            }\n",
    "            clinician_rec = (clin_index.get(ts, {}) or {}).get(dev)\n",
    "            if clinician_rec:\n",
    "                cases.append({\n",
    "                    \"case_id\": f\"{ts}::{dev}\",\n",
    "                    \"timestamp\": ts,\n",
    "                    \"device_id\": dev,\n",
    "                    \"analyzer\": analyzer_rec,\n",
    "                    \"clinician\": clinician_rec,\n",
    "                })\n",
    "    return cases\n",
    "\n",
    "# ---------- Build SMART-goal cases (rubric-driven) ----------\n",
    "def _build_smart_goal_cases(runs):\n",
    "    \"\"\"\n",
    "    Flatten SMART goals from analyzer_output.smart_goals.\n",
    "    Each case contains goal text plus a default SMART rubric the judge can use.\n",
    "    \"\"\"\n",
    "    cases = []\n",
    "    for run in runs:\n",
    "        ts = run.get(\"timestamp\", \"\")\n",
    "        ao = run.get(\"analyzer_output\") or {}\n",
    "        goals = ao.get(\"smart_goals\") or []\n",
    "        for g in goals:\n",
    "            num = g.get(\"goal_number\")\n",
    "            desc = g.get(\"description\", \"\")\n",
    "            cases.append({\n",
    "                \"case_id\": f\"{ts}::goal_{num}\",\n",
    "                \"timestamp\": ts,\n",
    "                \"goal_number\": num,\n",
    "                \"goal_text\": desc,\n",
    "            })\n",
    "    return cases\n",
    "\n",
    "# ---------- Planning tool that abstracts use cases ----------\n",
    "@tool\n",
    "def build_eval_plan(limit: int | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Decide which evaluation to run based on analyzer_outputs.jsonl contents.\n",
    "    Returns a plan with:\n",
    "      {\n",
    "        \"evaluation_type\": \"engagement_vs_clinician\" | \"smart_goals_rubric\",\n",
    "        \"metrics\": [\"...\"],\n",
    "        \"rubric\": { ... optional ... },\n",
    "        \"cases\": [ ... normalized cases ... ]\n",
    "      }\n",
    "    \"\"\"\n",
    "    runs = load_analyzer_runs(limit=limit)[\"runs\"]\n",
    "    clinicians = load_clinician_eval()[\"items\"]\n",
    "\n",
    "    # Heuristic: if analyzer_output has 'recommendations' (device_id...), prefer engagement;\n",
    "    # if analyzer_output has 'smart_goals', prefer SMART rubric mode.\n",
    "    has_engagement = any((r.get(\"analyzer_output\") or {}).get(\"recommendations\") for r in runs)\n",
    "    has_smart = any((r.get(\"analyzer_output\") or {}).get(\"smart_goals\") for r in runs)\n",
    "\n",
    "    if has_engagement and clinicians:\n",
    "        cases = _build_engagement_cases(runs, clinicians)\n",
    "        return {\n",
    "            \"evaluation_type\": \"engagement_vs_clinician\",\n",
    "            \"metrics\": [\"correctness\", \"completeness\", \"helpfulness\", \"coherence\", \"relevance\"],\n",
    "            \"rubric\": {\n",
    "                \"notes\": \"Compare analyzer category & rationale to clinician's.\",\n",
    "                \"agreement_rules\": {\n",
    "                    \"match\": \"same category (case-insensitive)\",\n",
    "                    \"partial\": \"different category but rationale overlaps clinician intent\",\n",
    "                    \"mismatch\": \"different with little/no overlap\",\n",
    "                }\n",
    "            },\n",
    "            \"cases\": cases\n",
    "        }\n",
    "\n",
    "    if has_smart:\n",
    "        cases = _build_smart_goal_cases(runs)\n",
    "        return {\n",
    "            \"evaluation_type\": \"smart_goals_rubric\",\n",
    "            \"metrics\": [\"specific\", \"measurable\", \"achievable\", \"relevant\", \"time_bound\", \"clarity\"],\n",
    "            \"rubric\": {\n",
    "                \"specific\":   \"Clearly states the behavior/target (who/what/when/where).\",\n",
    "                \"measurable\": \"Includes a quantifiable criterion (count, frequency, value).\",\n",
    "                \"achievable\": \"Feasible for the patient (resources/constraints).\",\n",
    "                \"relevant\":   \"Aligned to diabetes/health needs in the notes.\",\n",
    "                \"time_bound\": \"Contains a concrete timeframe or deadline.\",\n",
    "                \"clarity\":    \"Readable, unambiguous, free of contradictions.\"\n",
    "            },\n",
    "            \"cases\": cases\n",
    "        }\n",
    "\n",
    "    # Fallback: nothing to evaluate\n",
    "    return {\n",
    "        \"evaluation_type\": \"none\",\n",
    "        \"metrics\": [],\n",
    "        \"rubric\": {},\n",
    "        \"cases\": []\n",
    "    }\n",
    "\n",
    "# ---------- Evaluator Agent (general, plan-driven) ----------\n",
    "EVALUATOR_PROMPT = \"\"\"\n",
    "You are an Evaluator (LLM-as-Judge) that supports multiple evaluation modes via a plan.\n",
    "\n",
    "You will be given a plan from the tool build_eval_plan(limit) with:\n",
    "- evaluation_type: \"engagement_vs_clinician\" or \"smart_goals_rubric\"\n",
    "- metrics: list of metric names to score in [0.0, 1.0]\n",
    "- rubric: guidance for scoring\n",
    "- cases: a list of cases to evaluate\n",
    "\n",
    "CALLS:\n",
    "1) Call build_eval_plan(limit) EXACTLY ONCE (use the user-provided {\"limit\":N} if present; otherwise none).\n",
    "\n",
    "SCORING:\n",
    "- For \"engagement_vs_clinician\":\n",
    "  Each case has:\n",
    "    { case_id, timestamp, device_id, analyzer{category_recommended, rationale}, clinician{category_recommended, rationale} }\n",
    "  Score metrics: correctness, completeness, helpfulness, coherence, relevance.\n",
    "  Also produce:\n",
    "    agreement = \"match\" | \"partial\" | \"mismatch\"\n",
    "  Rules:\n",
    "    - match if categories are the same (case-insensitive).\n",
    "    - partial if different but analyzer rationale substantially overlaps clinician intent.\n",
    "    - mismatch otherwise.\n",
    "\n",
    "- For \"smart_goals_rubric\":\n",
    "  Each case has:\n",
    "    { case_id, timestamp, goal_number, goal_text }\n",
    "  Score metrics: specific, measurable, achievable, relevant, time_bound, clarity.\n",
    "  Focus only on the goal_text vs rubric. If unsafe, note it briefly.\n",
    "\n",
    "OUTPUT: STRICT JSON ONLY:\n",
    "{\n",
    "  \"evaluation_type\": \"string\",\n",
    "  \"cases_scored\": 0,\n",
    "  \"scores\": [\n",
    "    {\n",
    "      \"case_id\": \"string\",\n",
    "      \"metric_scores\": { \"<metric>\": 0.0 },\n",
    "      \"agreement\": \"match|partial|mismatch|n/a\",\n",
    "      \"notes\": \"short justification (<=40 words)\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "PROCESS:\n",
    "- Produce one score object per case with values in [0.0, 1.0].\n",
    "- Use \"agreement\":\"n/a\" for smart_goals_rubric (no clinician).\n",
    "- Keep notes concise and specific.\n",
    "\"\"\"\n",
    "\n",
    "evaluator_agent = Agent(\n",
    "    model=BedrockModel(\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"),\n",
    "    system_prompt=EVALUATOR_PROMPT,\n",
    "    tools=[build_eval_plan],  # single entry tool that returns everything needed\n",
    ")\n",
    "\n",
    "# ---------- Runner (single call) ----------\n",
    "def run_evaluator(limit: int | None = None, print_json: bool = True):\n",
    "    payload = {\"limit\": limit} if limit else {}\n",
    "    raw = evaluator_agent(json.dumps(payload))\n",
    "    out = _coerce_json(raw)\n",
    "\n",
    "    # Compute overall means dynamically across whatever metric set came back\n",
    "    metrics = set()\n",
    "    for s in out.get(\"scores\", []):\n",
    "        for k in (s.get(\"metric_scores\") or {}).keys():\n",
    "            metrics.add(k)\n",
    "    metrics = sorted(metrics)\n",
    "\n",
    "    buckets = {k: [] for k in metrics}\n",
    "    for s in out.get(\"scores\", []):\n",
    "        for k in metrics:\n",
    "            v = (s.get(\"metric_scores\") or {}).get(k)\n",
    "            if isinstance(v, (int, float)):\n",
    "                buckets[k].append(float(v))\n",
    "\n",
    "    overall = {k: (round(mean(buckets[k]), 4) if buckets[k] else 0.0) for k in metrics}\n",
    "    out[\"cases_scored\"] = len(out.get(\"scores\", []))\n",
    "    out[\"overall\"] = overall\n",
    "\n",
    "    _append_jsonl(EVAL_JSONL, {\n",
    "        \"run_id\": str(uuid.uuid4()),\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "        \"evaluator_output\": out\n",
    "    })\n",
    "\n",
    "    return\n",
    "\n",
    "# ---- run ----\n",
    "run_evaluator()           # evaluate all available cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf2bbf-daf6-4c02-bc01-a8652dbd6796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182976c4-4a29-415a-9242-f56d905a3a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375f780-a374-40b7-abd4-7d0bbf4054fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
