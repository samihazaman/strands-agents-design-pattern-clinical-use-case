{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16dbea56-9839-4402-b9ef-b22f1912f9a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:35:21.899925Z",
     "iopub.status.busy": "2025-08-15T00:35:21.899558Z",
     "iopub.status.idle": "2025-08-15T00:35:22.071696Z",
     "shell.execute_reply": "2025-08-15T00:35:22.070724Z",
     "shell.execute_reply.started": "2025-08-15T00:35:21.899893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohttp==3.12.13\n",
      "boto3==1.38.39\n",
      "botocore==1.38.39\n",
      "sagemaker==2.247.0\n",
      "litellm==1.72.2\n",
      "strands-agents==0.1.6\n",
      "strands-agents-builder==0.1.2\n",
      "strands-agents-tools==0.1.4\n",
      "matplotlib==3.10.3\n",
      "pandas==2.3.0\n",
      "seaborn==0.13.2\n",
      "joblib==1.5.1\n",
      "requests==2.32.4\n",
      "uv==0.7.13"
     ]
    }
   ],
   "source": [
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7ef95d8-5db5-4a31-94bf-4bcb42423bda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:35:27.297453Z",
     "iopub.status.busy": "2025-08-15T00:35:27.297163Z",
     "iopub.status.idle": "2025-08-15T00:35:27.300873Z",
     "shell.execute_reply": "2025-08-15T00:35:27.300119Z",
     "shell.execute_reply.started": "2025-08-15T00:35:27.297427Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c50c54e-62fd-4c9f-85fb-0246ce8a39ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:35:28.043392Z",
     "iopub.status.busy": "2025-08-15T00:35:28.042808Z",
     "iopub.status.idle": "2025-08-15T00:35:35.230863Z",
     "shell.execute_reply": "2025-08-15T00:35:35.229926Z",
     "shell.execute_reply.started": "2025-08-15T00:35:28.043367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping autogluon-multimodal as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping autogluon-timeseries as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping autogluon-features as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping autogluon-common as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping autogluon-core as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.21.1 requires botocore<1.37.2,>=1.37.0, but you have botocore 1.38.39 which is incompatible.\n",
      "sagemaker-studio-analytics-extension 0.2.0 requires sparkmagic==0.22.0, but you have sparkmagic 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Warnings are safe to ignore\n",
    "%pip uninstall -q -y autogluon-multimodal autogluon-timeseries autogluon-features autogluon-common autogluon-core\n",
    "%pip install -r requirements.txt -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b7e8f71-fc23-451f-93f2-b1bbd920f30b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:35:35.232713Z",
     "iopub.status.busy": "2025-08-15T00:35:35.232481Z",
     "iopub.status.idle": "2025-08-15T00:35:36.894048Z",
     "shell.execute_reply": "2025-08-15T00:35:36.893133Z",
     "shell.execute_reply.started": "2025-08-15T00:35:35.232690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q boto3 python-docx PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0211748-0a2c-436a-93ff-8227fb2b575e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:35:41.072053Z",
     "iopub.status.busy": "2025-08-15T00:35:41.071739Z",
     "iopub.status.idle": "2025-08-15T00:35:41.080518Z",
     "shell.execute_reply": "2025-08-15T00:35:41.079446Z",
     "shell.execute_reply.started": "2025-08-15T00:35:41.072024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1699afe5-6a3b-46f8-830a-3077f791bb89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:35:45.128651Z",
     "iopub.status.busy": "2025-08-15T00:35:45.127973Z",
     "iopub.status.idle": "2025-08-15T00:35:48.816277Z",
     "shell.execute_reply": "2025-08-15T00:35:48.815345Z",
     "shell.execute_reply.started": "2025-08-15T00:35:45.128621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.12/site-packages (1.38.39)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.40.10-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore<1.41.0,>=1.40.10 (from boto3)\n",
      "  Using cached botocore-1.40.10-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /opt/conda/lib/python3.12/site-packages (from boto3) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.10->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.10->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.10->boto3) (1.17.0)\n",
      "Using cached boto3-1.40.10-py3-none-any.whl (140 kB)\n",
      "Using cached botocore-1.40.10-py3-none-any.whl (14.0 MB)\n",
      "Installing collected packages: botocore, boto3\n",
      "\u001b[2K  Attempting uninstall: botocore\n",
      "\u001b[2K    Found existing installation: botocore 1.38.39\n",
      "\u001b[2K    Uninstalling botocore-1.38.39:\n",
      "\u001b[2K      Successfully uninstalled botocore-1.38.39\n",
      "\u001b[2K  Attempting uninstall: boto3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [botocore]\n",
      "\u001b[2K    Found existing installation: boto3 1.38.390m \u001b[32m0/2\u001b[0m [botocore]\n",
      "\u001b[2K    Uninstalling boto3-1.38.39:━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [botocore]\n",
      "\u001b[2K      Successfully uninstalled boto3-1.38.39\u001b[0m \u001b[32m0/2\u001b[0m [botocore]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [boto3]32m1/2\u001b[0m [boto3]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.21.1 requires botocore<1.37.2,>=1.37.0, but you have botocore 1.40.10 which is incompatible.\n",
      "sagemaker-studio-analytics-extension 0.2.0 requires sparkmagic==0.22.0, but you have sparkmagic 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.40.10 botocore-1.40.10\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd665cc-9725-49ce-9a54-82fd0be7bc82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:35:54.932478Z",
     "iopub.status.busy": "2025-08-15T00:35:54.931938Z",
     "iopub.status.idle": "2025-08-15T00:35:55.375150Z",
     "shell.execute_reply": "2025-08-15T00:35:55.374498Z",
     "shell.execute_reply.started": "2025-08-15T00:35:54.932444Z"
    }
   },
   "outputs": [],
   "source": [
    "#from utils.strands_sagemaker import SageMakerAIModel\n",
    "from strands.models.bedrock import BedrockModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531f9d3e-38c0-41c3-87b1-f46c980eace1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:35:55.914256Z",
     "iopub.status.busy": "2025-08-15T00:35:55.913473Z",
     "iopub.status.idle": "2025-08-15T00:35:55.998709Z",
     "shell.execute_reply": "2025-08-15T00:35:55.998072Z",
     "shell.execute_reply.started": "2025-08-15T00:35:55.914229Z"
    }
   },
   "outputs": [],
   "source": [
    "provider = \"BEDROCK\"  # Change this to SAGEMAKER to use the previously deployed endpoint instead of Bedrock\n",
    "\n",
    "match provider:\n",
    "    case \"BEDROCK\":\n",
    "        # Using Claude 3.5 Sonnet from Bedrock\n",
    "        model = BedrockModel(model_id=\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\")\n",
    "    case \"SAGEMAKER\":\n",
    "        # Using Qwen3 from our endpoint in SageMaker AI\n",
    "        model = SageMakerAIModel({\n",
    "            \"endpoint_name\": SAGEMAKER_ENDPOINT_NAME,\n",
    "            \"max_tokens\": 16*1024,\n",
    "            \"temperature\": 0.1,\n",
    "            \"stream\": False\n",
    "\t\t})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29eda0fd-80db-4b75-8dd6-a425b83f45a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:35:58.168163Z",
     "iopub.status.busy": "2025-08-15T00:35:58.167785Z",
     "iopub.status.idle": "2025-08-15T00:35:58.295377Z",
     "shell.execute_reply": "2025-08-15T00:35:58.294702Z",
     "shell.execute_reply.started": "2025-08-15T00:35:58.168133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "from strands_tools import http_request \n",
    "import json, time, uuid, re, requests\n",
    "import io\n",
    "import mimetypes\n",
    "from typing import Tuple\n",
    "try:\n",
    "    import boto3\n",
    "    from botocore.exceptions import BotoCoreError, ClientError\n",
    "except Exception:\n",
    "    boto3 = None\n",
    "\n",
    "try:\n",
    "    from PyPDF2 import PdfReader\n",
    "except Exception:\n",
    "    PdfReader = None\n",
    "\n",
    "try:\n",
    "    import docx  # python-docx\n",
    "except Exception:\n",
    "    docx = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4373ee99-3707-4a86-8886-d622d1b855f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T00:36:05.614323Z",
     "iopub.status.busy": "2025-08-15T00:36:05.613843Z",
     "iopub.status.idle": "2025-08-15T00:36:17.901439Z",
     "shell.execute_reply": "2025-08-15T00:36:17.900654Z",
     "shell.execute_reply.started": "2025-08-15T00:36:05.614298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool #1: fetch_data\n",
      "{\n",
      "  \"smart_goals\": [\n",
      "    {\n",
      "      \"goal_number\": 1,\n",
      "      \"description\": \"Reduce HbA1c from current 8.1% to below 7.0% within 3 months through medication adherence, blood glucose monitoring 4 times daily, and lifestyle modifications\"\n",
      "    },\n",
      "    {\n",
      "      \"goal_number\": 2,\n",
      "      \"description\": \"Achieve and maintain fasting blood glucose between 80-130 mg/dL and post-meal readings under 180 mg/dL within 4 weeks through proper medication timing and balanced meal planning\"\n",
      "    },\n",
      "    {\n",
      "      \"goal_number\": 3,\n",
      "      \"description\": \"Complete 150 minutes of moderate-intensity aerobic exercise (such as brisk walking or swimming) per week, plus strength training twice weekly, starting immediately\"\n",
      "    },\n",
      "    {\n",
      "      \"goal_number\": 4,\n",
      "      \"description\": \"Reduce weight from 185 lbs to 160-165 lbs over the next 6 months through portion control and balanced nutrition plan including 45-60 grams of carbs per meal\"\n",
      "    },\n",
      "    {\n",
      "      \"goal_number\": 5,\n",
      "      \"description\": \"Lower LDL cholesterol from 120 mg/dL to below 100 mg/dL within 3 months by increasing omega-3 rich foods and reducing trans fat intake\"\n",
      "    },\n",
      "    {\n",
      "      \"goal_number\": 6,\n",
      "      \"description\": \"Reduce blood pressure from 135/85 mmHg to below 130/80 mmHg within 2 months through reduced sodium intake and regular exercise\"\n",
      "    }\n",
      "  ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "# ================== Analyzer (data-source agnostic, single entry) ==================\n",
    "from strands import Agent, tool\n",
    "import json, os, time, uuid, re, requests\n",
    "\n",
    "# ---- environment time ----\n",
    "os.environ[\"TZ\"] = \"America/New_York\"\n",
    "if hasattr(time, \"tzset\"):\n",
    "    time.tzset()\n",
    "\n",
    "# ---- config / paths ----\n",
    "# Set this ONCE. It can be a URL (http/https) OR a local .txt file path.\n",
    "\n",
    "#Servlet\n",
    "'''\n",
    "DATA_SOURCE   = \"https://appserver2.sippasolutions.com/tomcat7/RemoteDBServlet-0.0.1-SNAPSHOT/DBServlet?secret=zaman@qcsurp2025clinical_use_case!\"\n",
    "ROW_DELIM     = \"@\"\n",
    "DATA_LOG_FILE = \"analyzer_raw_data_log.txt\"\n",
    "OUTPUT_JSONL  = \"analyzer_outputs.jsonl\"\n",
    "'''\n",
    "\n",
    "#txt file\n",
    "'''\n",
    "DATA_SOURCE   = \"patient_summary.txt\"\n",
    "ROW_DELIM     = \"@\"\n",
    "DATA_LOG_FILE = \"analyzer_raw__patient_summary_data_log.txt\"\n",
    "OUTPUT_JSONL  = \"analyzer_smart_goal_outputs.jsonl\"\n",
    "'''\n",
    "\n",
    "#S3\n",
    "DATA_SOURCE   = \"s3://patient-summary-bucket/10_other.docx\"\n",
    "ROW_DELIM     = \"@\"\n",
    "DATA_LOG_FILE = \"analyzer_raw_s3_data_log.txt\"\n",
    "OUTPUT_JSONL  = \"analyzer_s3_outputs.jsonl\"\n",
    "\n",
    "\n",
    "\n",
    "# ===== helpers =====\n",
    "def _format_rows_as_lines(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    If the data uses '@' as a row delimiter, split onto newlines.\n",
    "    Otherwise, return the text as-is (e.g., clinician notes).\n",
    "    \"\"\"\n",
    "    text = raw_text.strip()\n",
    "    if ROW_DELIM in text:\n",
    "        chunks = [c.strip() for c in text.split(ROW_DELIM) if c.strip()]\n",
    "        return \"\\n\".join(chunks)\n",
    "    return text\n",
    "\n",
    "def _save_formatted_to_file(formatted_text: str, log_path: str):\n",
    "    os.makedirs(os.path.dirname(log_path) or \".\", exist_ok=True)\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"\\n=== Run at {timestamp} ===\\n\")\n",
    "        f.write(formatted_text + \"\\n\")\n",
    "\n",
    "def _coerce_json(text: str):\n",
    "    \"\"\"\n",
    "    Extract the first JSON object from an LLM response and parse it.\n",
    "    \"\"\"\n",
    "    s = str(text).strip()\n",
    "    if s.startswith(\"{\") and s.endswith(\"}\"):\n",
    "        return json.loads(s)\n",
    "    m = re.search(r\"\\{.*\\}\", s, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"No JSON object found in agent output.\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "def _append_jsonl(path: str, obj: dict):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# ===== S3 helpers =====\n",
    "def _parse_s3_uri(uri: str) -> Tuple[str, str]:\n",
    "    # s3://bucket/key -> (bucket, key)\n",
    "    assert uri.lower().startswith(\"s3://\"), \"Not an s3:// URI\"\n",
    "    without = uri[5:]\n",
    "    parts = without.split(\"/\", 1)\n",
    "    bucket = parts[0]\n",
    "    key = parts[1] if len(parts) > 1 else \"\"\n",
    "    return bucket, key\n",
    "\n",
    "def _read_s3_object(uri: str) -> bytes:\n",
    "    if boto3 is None:\n",
    "        raise RuntimeError(\"boto3 not installed. Run: pip install boto3\")\n",
    "    bucket, key = _parse_s3_uri(uri)\n",
    "    s3 = boto3.client(\"s3\")  \n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "        return obj[\"Body\"].read()\n",
    "    except (BotoCoreError, ClientError) as e:\n",
    "        raise RuntimeError(f\"S3 read failed for {uri}: {e}\")\n",
    "\n",
    "def _ext_or_mime(uri: str, content_bytes: bytes) -> str:\n",
    "    # Guess from extension; if unknown, peek at header minimally\n",
    "    mime, _ = mimetypes.guess_type(uri)\n",
    "    return mime or \"application/octet-stream\"\n",
    "\n",
    "def _extract_text_from_bytes(uri: str, content: bytes) -> str:\n",
    "    mime = _ext_or_mime(uri, content)\n",
    "    # Prefer extension-based routing\n",
    "    luri = uri.lower()\n",
    "    if luri.endswith(\".pdf\") or mime == \"application/pdf\":\n",
    "        if PdfReader is None:\n",
    "            raise RuntimeError(\"PyPDF2 not installed. Run: pip install PyPDF2\")\n",
    "        reader = PdfReader(io.BytesIO(content))\n",
    "        parts = []\n",
    "        for page in reader.pages:\n",
    "            try:\n",
    "                parts.append(page.extract_text() or \"\")\n",
    "            except Exception:\n",
    "                continue\n",
    "        return \"\\n\".join(p.strip() for p in parts if p)\n",
    "    if luri.endswith(\".docx\") or mime in (\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\",):\n",
    "        if docx is None:\n",
    "            raise RuntimeError(\"python-docx not installed. Run: pip install python-docx\")\n",
    "        d = docx.Document(io.BytesIO(content))\n",
    "        return \"\\n\".join(p.text for p in d.paragraphs if p.text)\n",
    "    # Fallback: treat as UTF-8 text\n",
    "    try:\n",
    "        return content.decode(\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        return content.decode(\"latin-1\", errors=\"ignore\")\n",
    "\n",
    "# ===== unified fetch tool (uses only DATA_SOURCE from config,  (URL / file / S3)) =====\n",
    "@tool\n",
    "def fetch_data() -> dict:\n",
    "    \"\"\"\n",
    "    Fetches data from the configured DATA_SOURCE (URL or local file).\n",
    "      - If DATA_SOURCE is http/https: HTTP POST with empty body {}\n",
    "      - If DATA_SOURCE is a file path: read text from the file\n",
    "      - If DATA_SOURCE is S3: s3://bucket/key: download securely using boto3 and extract text (PDF/DOCX/TXT)\n",
    "\n",
    "    Returns:\n",
    "      {\n",
    "        \"raw_text\": string,\n",
    "        \"formatted_text\": string,   # '@' rows split to newlines if present\n",
    "        \"meta\": {\"source_type\": \"url\"|\"file\"|\"s3\", \"data_source\": string}\n",
    "      }\n",
    "    \"\"\"\n",
    "    ds = DATA_SOURCE\n",
    "\n",
    "\n",
    "    # S3 branch\n",
    "    if isinstance(ds, str) and ds.lower().startswith(\"s3://\"):\n",
    "        try:\n",
    "            blob = _read_s3_object(ds)\n",
    "            raw_text = _extract_text_from_bytes(ds, blob)\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"S3 error: {e}\", \"raw_text\": \"\", \"formatted_text\": \"\", \"meta\": {\"source_type\": \"s3\", \"data_source\": ds}}\n",
    "        formatted = _format_rows_as_lines(raw_text)\n",
    "        # Optional audit log:\n",
    "        _save_formatted_to_file(formatted, DATA_LOG_FILE)\n",
    "        return {\"raw_text\": raw_text, \"formatted_text\": formatted, \"meta\": {\"source_type\": \"s3\", \"data_source\": ds}}\n",
    "    \n",
    "    # URL branch\n",
    "    if isinstance(ds, str) and ds.lower().startswith((\"http://\", \"https://\")):\n",
    "        try:\n",
    "            resp = requests.post(ds, data={}, timeout=60)\n",
    "            resp.raise_for_status()\n",
    "            raw = resp.text\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"HTTP error: {e}\", \"raw_text\": \"\", \"formatted_text\": \"\", \"meta\": {\"source_type\": \"url\", \"data_source\": ds}}\n",
    "        formatted = _format_rows_as_lines(raw)\n",
    "        # Log servlet-like pulls for audit\n",
    "        _save_formatted_to_file(formatted, DATA_LOG_FILE)\n",
    "        return {\"raw_text\": raw, \"formatted_text\": formatted, \"meta\": {\"source_type\": \"url\", \"data_source\": ds}}\n",
    "\n",
    "    # File branch\n",
    "    if isinstance(ds, str) and os.path.exists(ds):\n",
    "        try:\n",
    "            # If it's a binary (pdf/docx), read bytes and extract text\n",
    "            if ds.lower().endswith((\".pdf\", \".docx\")):\n",
    "                with open(ds, \"rb\") as f:\n",
    "                    content = f.read()\n",
    "                raw_text = _extract_text_from_bytes(ds, content)\n",
    "            else:\n",
    "                with open(ds, \"r\", encoding=\"utf-8\") as f:\n",
    "                    raw_text = f.read()\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"File read error: {e}\", \"raw_text\": \"\", \"formatted_text\": \"\", \"meta\": {\"source_type\": \"file\", \"data_source\": ds}}\n",
    "        formatted = _format_rows_as_lines(raw_text)\n",
    "        return {\"raw_text\": raw_text, \"formatted_text\": formatted, \"meta\": {\"source_type\": \"file\", \"data_source\": ds}}\n",
    "\n",
    "    # Unknown source\n",
    "    return {\"error\": f\"DATA_SOURCE not found or unsupported: {ds}\", \"raw_text\": \"\", \"formatted_text\": \"\", \"meta\": {\"source_type\": \"unknown\", \"data_source\": str(ds)}}\n",
    "\n",
    "# ===== generic analyzer prompt =====\n",
    "# Edit ONLY this system prompt to change the task and required output JSON.\n",
    "ANALYZER_PROMPT = \"\"\"\n",
    "You are an Analyzer Agent.\n",
    "\n",
    "Tool available:\n",
    "- fetch_data() -> {raw_text, formatted_text, meta}\n",
    "\n",
    "You will receive an empty JSON input. IGNORE any user content and:\n",
    "INSTRUCTIONS:\n",
    "1) Call fetch_data EXACTLY ONCE (no arguments). It reads the configured DATA_SOURCE.\n",
    "2) Use \"formatted_text\" as your working input. It is newline-separated if the source used '@' row delimiters; otherwise it may be free text/paragraphs.\n",
    "3) Perform the analysis according to the TASK below.\n",
    "4) Produce output that matches the OUTPUT CONTRACT below EXACTLY (keys and structure). Output ONLY that JSON object and nothing else.\n",
    "5) Do not call any other tools. Do not print anything except the final JSON. Do not retry fetch_data.\n",
    "\n",
    "DEFAULT TASK (you may replace this entire task text to repurpose the agent):\n",
    "- Derive from the following content SMART goals that are specific, measurable, actionable, relevant and time-bounded: {DATA_SOURCE}\"\n",
    "\n",
    "\n",
    "DEFAULT OUTPUT CONTRACT (you may replace this to another JSON contract):\n",
    "{\n",
    "  \"smart_goals\": [\n",
    "    {\n",
    "      \"goal_number\": \"integer (starts at 1 and increments for each goal)\",\n",
    "      \"description\": \"string (time-bound, measurable details)\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "analyzer_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=ANALYZER_PROMPT,\n",
    "    tools=[fetch_data],\n",
    ")\n",
    "\n",
    "# ===== Run the agent directly =====\n",
    "payload = {}  # always empty\n",
    "raw_response = analyzer_agent(json.dumps(payload))\n",
    "\n",
    "# Parse to clean JSON and save\n",
    "parsed = _coerce_json(raw_response)\n",
    "_append_jsonl(OUTPUT_JSONL, {\n",
    "    \"run_id\": str(uuid.uuid4()),\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "    \"data_source\": DATA_SOURCE,\n",
    "    \"analyzer_output\": parsed\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832b19c-3445-476c-8406-ead8edd5c7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba56dac-bbb6-4423-8360-ab606c0f4fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191cebfa-29a2-4a63-b4b6-c15313759e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31aa82fe-585b-4274-baee-869cc67a8701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T18:22:02.142816Z",
     "iopub.status.busy": "2025-08-14T18:22:02.142263Z",
     "iopub.status.idle": "2025-08-14T18:23:13.053901Z",
     "shell.execute_reply": "2025-08-14T18:23:13.053195Z",
     "shell.execute_reply.started": "2025-08-14T18:22:02.142711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help evaluate the cases. Let me first get the evaluation plan.\n",
      "Tool #2: build_eval_plan\n",
      "I'll evaluate these SMART goals using the provided rubric. Here's my evaluation in the required JSON format:\n",
      "\n",
      "{\n",
      "  \"evaluation_type\": \"smart_goals_rubric\",\n",
      "  \"cases_scored\": 10,\n",
      "  \"scores\": [\n",
      "    {\n",
      "      \"case_id\": \"2025-08-14 00:56:21::goal_1\",\n",
      "      \"metric_scores\": {\n",
      "        \"specific\": 1.0,\n",
      "        \"measurable\": 1.0,\n",
      "        \"achievable\": 0.9,\n",
      "        \"relevant\": 1.0,\n",
      "        \"time_bound\": 1.0,\n",
      "        \"clarity\": 1.0\n",
      "      },\n",
      "      \"agreement\": \"n/a\",\n",
      "      \"notes\": \"Clear target values, monitoring frequency, and timeframe. Highly specific and measurable glucose management plan.\"\n",
      "    },\n",
      "    {\n",
      "      \"case_id\": \"2025-08-14 00:56:21::goal_2\",\n",
      "      \"metric_scores\": {\n",
      "        \"specific\": 1.0,\n",
      "        \"measurable\": 1.0,\n",
      "        \"achievable\": 0.9,\n",
      "        \"relevant\": 1.0,\n",
      "        \"time_bound\": 0.7,\n",
      "        \"clarity\": 1.0\n",
      "      },\n",
      "      \"agreement\": \"n/a\",\n",
      "      \"notes\": \"Precise exercise requirements but lacks overall timeframe for goal completion.\"\n",
      "    },\n",
      "    {\n",
      "      \"case_id\": \"2025-08-14 00:56:21::goal_3\",\n",
      "      \"metric_scores\": {\n",
      "        \"specific\": 0.9,\n",
      "        \"measurable\": 1.0,\n",
      "        \"achievable\": 0.8,\n",
      "        \"relevant\": 1.0,\n",
      "        \"time_bound\": 1.0,\n",
      "        \"clarity\": 0.9\n",
      "      },\n",
      "      \"agreement\": \"n/a\",\n",
      "      \"notes\": \"Clear target weight and timeline, but prescribed portions could be more specific.\"\n",
      "    },\n",
      "    {\n",
      "      \"case_id\": \"2025-08-14 00:56:21::goal_4\",\n",
      "      \"metric_scores\": {\n",
      "        \"specific\": 1.0,\n",
      "        \"measurable\": 1.0,\n",
      "        \"achievable\": 0.9,\n",
      "        \"relevant\": 1.0,\n",
      "        \"time_bound\": 0.8,\n",
      "        \"clarity\": 1.0\n",
      "      },\n",
      "      \"agreement\": \"n/a\",\n",
      "      \"notes\": \"Well-defined cholesterol targets with quarterly checks. Methods clearly stated.\"\n",
      "    },\n",
      "    {\n",
      "      \"case_id\": \"2025-08-14 00:56:21::goal_5\",\n",
      "      \"metric_scores\": {\n",
      "        \"specific\": 0.9,\n",
      "        \"measurable\": 0.8,\n",
      "        \"achievable\": 0.9,\n",
      "        \"relevant\": 1.0,\n",
      "        \"time_bound\": 0.7,\n",
      "        \"clarity\": 0.9\n",
      "      },\n",
      "      \"agreement\": \"n/a\",\n",
      "      \"notes\": \"Clear BP target but could specify monitoring frequency and overall timeline.\"\n",
      "    },\n",
      "    {\n",
      "      \"case_id\": \"2025-08-14 14:21:49::goal_1\",\n",
      "      \"metric_scores\": {\n",
      "        \"specific\": 1.0,\n",
      "        \"measurable\": 1.0,\n",
      "        \"achievable\": 0.9,\n",
      "        \"relevant\": 1.0,\n",
      "        \"time_bound\": 1.0,\n",
      "        \"clarity\": 1.0\n",
      "      },\n",
      "      \"agreement\": \"n/a\",\n",
      "      \"notes\": \"Identical to earlier goal - comprehensive glucose management plan with clear metrics.\"\n",
      "    },\n",
      "    {\n",
      "      \"case_id\": \"2025-08-14 14:21:49::goal_2\",\n",
      "      \"metric_scores\": {\n",
      "        \"specific\": 1.0,\n",
      "        \"measurable\": 1.0,\n",
      "        \"achievable\": 0.9,\n",
      "        \"relevant\": 1.0,\n",
      "        \"time_bound\": 1.0,\n",
      "        \"clarity\": 1.0\n",
      "      },\n",
      "      \"agreement\": \"n/a\",\n",
      "      \"notes\": \"Improved version with clear 12-week timeline and specific exercise requirements.\"\n",
      "    },\n",
      "    {\n",
      "      \"case_id\": \"2025-08-14 14:21:49::goal_3\",\n",
      "      \"metric_scores\": {\n",
      "        \"specific\": 1.0,\n",
      "        \"measurable\": 1.0,\n",
      "        \"achievable\": 0.9,\n",
      "        \"relevant\": 1.0,\n",
      "        \"time_bound\": 1.0,\n",
      "        \"clarity\": 1.0\n",
      "      },\n",
      "      \"agreement\": \"n/a\",\n",
      "      \"notes\": \"Added specific weight loss rate (1-2 lbs/week), making it more measurable.\"\n",
      "    },\n",
      "    {\n",
      "      \"case_id\": \"2025-08-14 14:21:49::goal_4\",\n",
      "      \"metric_scores\": {\n",
      "        \"specific\": 0.9,\n",
      "        \"measurable\": 1.0,\n",
      "        \"achievable\": 0.9,\n",
      "        \"relevant\": 1.0,\n",
      "        \"time_bound\": 1.0,\n",
      "        \"clarity\": 0.9\n",
      "      },\n",
      "      \"agreement\": \"n/a\",\n",
      "      \"notes\": \"Clear cholesterol targets and timeline, but could specify dietary changes more.\"\n",
      "    },\n",
      "    {\n",
      "      \"case_id\": \"2025-08-14 14:21:49::goal_5\",\n",
      "      \"metric_scores\": {\n",
      "        \"specific\": 1.0,\n",
      "        \"measurable\": 1.0,\n",
      "        \"achievable\": 1.0,\n",
      "        \"relevant\": 1.0,\n",
      "        \"time_bound\": 1.0,\n",
      "        \"clarity\": 1.0\n",
      "      },\n",
      "      \"agreement\": \"n/a\",\n",
      "      \"notes\": \"Excellent schedule for monitoring with clear timeframe and purpose.\"\n",
      "    }\n",
      "  ]\n",
      "}"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'evaluation_type': 'smart_goals_rubric',\n",
       " 'cases_scored': 10,\n",
       " 'scores': [{'case_id': '2025-08-14 00:56:21::goal_1',\n",
       "   'metric_scores': {'specific': 1.0,\n",
       "    'measurable': 1.0,\n",
       "    'achievable': 0.9,\n",
       "    'relevant': 1.0,\n",
       "    'time_bound': 1.0,\n",
       "    'clarity': 1.0},\n",
       "   'agreement': 'n/a',\n",
       "   'notes': 'Clear target values, monitoring frequency, and timeframe. Highly specific and measurable glucose management plan.'},\n",
       "  {'case_id': '2025-08-14 00:56:21::goal_2',\n",
       "   'metric_scores': {'specific': 1.0,\n",
       "    'measurable': 1.0,\n",
       "    'achievable': 0.9,\n",
       "    'relevant': 1.0,\n",
       "    'time_bound': 0.7,\n",
       "    'clarity': 1.0},\n",
       "   'agreement': 'n/a',\n",
       "   'notes': 'Precise exercise requirements but lacks overall timeframe for goal completion.'},\n",
       "  {'case_id': '2025-08-14 00:56:21::goal_3',\n",
       "   'metric_scores': {'specific': 0.9,\n",
       "    'measurable': 1.0,\n",
       "    'achievable': 0.8,\n",
       "    'relevant': 1.0,\n",
       "    'time_bound': 1.0,\n",
       "    'clarity': 0.9},\n",
       "   'agreement': 'n/a',\n",
       "   'notes': 'Clear target weight and timeline, but prescribed portions could be more specific.'},\n",
       "  {'case_id': '2025-08-14 00:56:21::goal_4',\n",
       "   'metric_scores': {'specific': 1.0,\n",
       "    'measurable': 1.0,\n",
       "    'achievable': 0.9,\n",
       "    'relevant': 1.0,\n",
       "    'time_bound': 0.8,\n",
       "    'clarity': 1.0},\n",
       "   'agreement': 'n/a',\n",
       "   'notes': 'Well-defined cholesterol targets with quarterly checks. Methods clearly stated.'},\n",
       "  {'case_id': '2025-08-14 00:56:21::goal_5',\n",
       "   'metric_scores': {'specific': 0.9,\n",
       "    'measurable': 0.8,\n",
       "    'achievable': 0.9,\n",
       "    'relevant': 1.0,\n",
       "    'time_bound': 0.7,\n",
       "    'clarity': 0.9},\n",
       "   'agreement': 'n/a',\n",
       "   'notes': 'Clear BP target but could specify monitoring frequency and overall timeline.'},\n",
       "  {'case_id': '2025-08-14 14:21:49::goal_1',\n",
       "   'metric_scores': {'specific': 1.0,\n",
       "    'measurable': 1.0,\n",
       "    'achievable': 0.9,\n",
       "    'relevant': 1.0,\n",
       "    'time_bound': 1.0,\n",
       "    'clarity': 1.0},\n",
       "   'agreement': 'n/a',\n",
       "   'notes': 'Identical to earlier goal - comprehensive glucose management plan with clear metrics.'},\n",
       "  {'case_id': '2025-08-14 14:21:49::goal_2',\n",
       "   'metric_scores': {'specific': 1.0,\n",
       "    'measurable': 1.0,\n",
       "    'achievable': 0.9,\n",
       "    'relevant': 1.0,\n",
       "    'time_bound': 1.0,\n",
       "    'clarity': 1.0},\n",
       "   'agreement': 'n/a',\n",
       "   'notes': 'Improved version with clear 12-week timeline and specific exercise requirements.'},\n",
       "  {'case_id': '2025-08-14 14:21:49::goal_3',\n",
       "   'metric_scores': {'specific': 1.0,\n",
       "    'measurable': 1.0,\n",
       "    'achievable': 0.9,\n",
       "    'relevant': 1.0,\n",
       "    'time_bound': 1.0,\n",
       "    'clarity': 1.0},\n",
       "   'agreement': 'n/a',\n",
       "   'notes': 'Added specific weight loss rate (1-2 lbs/week), making it more measurable.'},\n",
       "  {'case_id': '2025-08-14 14:21:49::goal_4',\n",
       "   'metric_scores': {'specific': 0.9,\n",
       "    'measurable': 1.0,\n",
       "    'achievable': 0.9,\n",
       "    'relevant': 1.0,\n",
       "    'time_bound': 1.0,\n",
       "    'clarity': 0.9},\n",
       "   'agreement': 'n/a',\n",
       "   'notes': 'Clear cholesterol targets and timeline, but could specify dietary changes more.'},\n",
       "  {'case_id': '2025-08-14 14:21:49::goal_5',\n",
       "   'metric_scores': {'specific': 1.0,\n",
       "    'measurable': 1.0,\n",
       "    'achievable': 1.0,\n",
       "    'relevant': 1.0,\n",
       "    'time_bound': 1.0,\n",
       "    'clarity': 1.0},\n",
       "   'agreement': 'n/a',\n",
       "   'notes': 'Excellent schedule for monitoring with clear timeframe and purpose.'}],\n",
       " 'overall': {'achievable': 0.9,\n",
       "  'clarity': 0.97,\n",
       "  'measurable': 0.98,\n",
       "  'relevant': 1.0,\n",
       "  'specific': 0.97,\n",
       "  'time_bound': 0.92}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from strands import Agent, tool\n",
    "import json, os, time, uuid, re\n",
    "from statistics import mean\n",
    "\n",
    "# ---------- Paths ----------\n",
    "ANALYZER_JSONL = \"analyzer_smart_goal_outputs.jsonl\"     # produced by the Analyzer\n",
    "CLINICIAN_JSON = \"clinician_evaluation.json\"  # optional: only used for engagement eval\n",
    "EVAL_JSONL     = \"evaluator_runs.jsonl\"\n",
    "\n",
    "# ---------- File helpers ----------\n",
    "def _read_jsonl(path: str):\n",
    "    items = []\n",
    "    if not os.path.exists(path):\n",
    "        return items\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                items.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return items\n",
    "\n",
    "def _read_json(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def _append_jsonl(path: str, obj: dict):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def _coerce_json(text: str):\n",
    "    s = str(text).strip()\n",
    "    if s.startswith(\"{\") and s.endswith(\"}\"):\n",
    "        return json.loads(s)\n",
    "    m = re.search(r\"\\{.*\\}\", s, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"No JSON object found in evaluator output.\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "# ---------- Low-level loaders as tools ----------\n",
    "@tool\n",
    "def load_analyzer_runs(limit: int | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Load analyzer outputs (JSONL), sorted by timestamp ASC. Optionally keep only latest 'limit'.\n",
    "    \"\"\"\n",
    "    runs = _read_jsonl(ANALYZER_JSONL)\n",
    "    runs.sort(key=lambda r: r.get(\"timestamp\", \"\"))\n",
    "    if limit:\n",
    "        runs = runs[-limit:]\n",
    "    return {\"runs\": runs}\n",
    "\n",
    "@tool\n",
    "def load_clinician_eval() -> dict:\n",
    "    \"\"\"\n",
    "    Load clinician_evaluation.json (array), sorted by timestamp ASC (optional for SMART).\n",
    "    \"\"\"\n",
    "    items = _read_json(CLINICIAN_JSON)\n",
    "    items.sort(key=lambda r: r.get(\"timestamp\", \"\"))\n",
    "    return {\"items\": items}\n",
    "\n",
    "# ---------- Build Engagement pairs: analyzer vs clinician ----------\n",
    "def _build_engagement_cases(runs, clinician_items):\n",
    "    # index clinician by timestamp -> {device_id -> rec}\n",
    "    clin_index = {}\n",
    "    for row in clinician_items:\n",
    "        ts = row.get(\"timestamp\", \"\")\n",
    "        for rec in row.get(\"clinician_output\", {}).get(\"recommendations\", []):\n",
    "            clin_index.setdefault(ts, {})[rec.get(\"device_id\")] = {\n",
    "                \"category_recommended\": rec.get(\"category_recommended\"),\n",
    "                \"rationale\": rec.get(\"rationale\"),\n",
    "            }\n",
    "\n",
    "    cases = []\n",
    "    for run in runs:\n",
    "        ts = run.get(\"timestamp\", \"\")\n",
    "        recs = (run.get(\"analyzer_output\") or {}).get(\"recommendations\", [])\n",
    "        for rec in recs:\n",
    "            dev = rec.get(\"device_id\")\n",
    "            analyzer_rec = {\n",
    "                \"category_recommended\": rec.get(\"category_recommended\"),\n",
    "                \"rationale\": rec.get(\"rationale\"),\n",
    "            }\n",
    "            clinician_rec = (clin_index.get(ts, {}) or {}).get(dev)\n",
    "            if clinician_rec:\n",
    "                cases.append({\n",
    "                    \"case_id\": f\"{ts}::{dev}\",\n",
    "                    \"timestamp\": ts,\n",
    "                    \"device_id\": dev,\n",
    "                    \"analyzer\": analyzer_rec,\n",
    "                    \"clinician\": clinician_rec,\n",
    "                })\n",
    "    return cases\n",
    "\n",
    "# ---------- Build SMART-goal cases (rubric-driven) ----------\n",
    "def _build_smart_goal_cases(runs):\n",
    "    \"\"\"\n",
    "    Flatten SMART goals from analyzer_output.smart_goals.\n",
    "    Each case contains goal text plus a default SMART rubric the judge can use.\n",
    "    \"\"\"\n",
    "    cases = []\n",
    "    for run in runs:\n",
    "        ts = run.get(\"timestamp\", \"\")\n",
    "        ao = run.get(\"analyzer_output\") or {}\n",
    "        goals = ao.get(\"smart_goals\") or []\n",
    "        for g in goals:\n",
    "            num = g.get(\"goal_number\")\n",
    "            desc = g.get(\"description\", \"\")\n",
    "            cases.append({\n",
    "                \"case_id\": f\"{ts}::goal_{num}\",\n",
    "                \"timestamp\": ts,\n",
    "                \"goal_number\": num,\n",
    "                \"goal_text\": desc,\n",
    "            })\n",
    "    return cases\n",
    "\n",
    "# ---------- Planning tool that abstracts use cases ----------\n",
    "@tool\n",
    "def build_eval_plan(limit: int | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Decide which evaluation to run based on analyzer_outputs.jsonl contents.\n",
    "    Returns a plan with:\n",
    "      {\n",
    "        \"evaluation_type\": \"engagement_vs_clinician\" | \"smart_goals_rubric\",\n",
    "        \"metrics\": [\"...\"],\n",
    "        \"rubric\": { ... optional ... },\n",
    "        \"cases\": [ ... normalized cases ... ]\n",
    "      }\n",
    "    \"\"\"\n",
    "    runs = load_analyzer_runs(limit=limit)[\"runs\"]\n",
    "    clinicians = load_clinician_eval()[\"items\"]\n",
    "\n",
    "    # Heuristic: if analyzer_output has 'recommendations' (device_id...), prefer engagement;\n",
    "    # if analyzer_output has 'smart_goals', prefer SMART rubric mode.\n",
    "    has_engagement = any((r.get(\"analyzer_output\") or {}).get(\"recommendations\") for r in runs)\n",
    "    has_smart = any((r.get(\"analyzer_output\") or {}).get(\"smart_goals\") for r in runs)\n",
    "\n",
    "    if has_engagement and clinicians:\n",
    "        cases = _build_engagement_cases(runs, clinicians)\n",
    "        return {\n",
    "            \"evaluation_type\": \"engagement_vs_clinician\",\n",
    "            \"metrics\": [\"correctness\", \"completeness\", \"helpfulness\", \"coherence\", \"relevance\"],\n",
    "            \"rubric\": {\n",
    "                \"notes\": \"Compare analyzer category & rationale to clinician's.\",\n",
    "                \"agreement_rules\": {\n",
    "                    \"match\": \"same category (case-insensitive)\",\n",
    "                    \"partial\": \"different category but rationale overlaps clinician intent\",\n",
    "                    \"mismatch\": \"different with little/no overlap\",\n",
    "                }\n",
    "            },\n",
    "            \"cases\": cases\n",
    "        }\n",
    "\n",
    "    if has_smart:\n",
    "        cases = _build_smart_goal_cases(runs)\n",
    "        return {\n",
    "            \"evaluation_type\": \"smart_goals_rubric\",\n",
    "            \"metrics\": [\"specific\", \"measurable\", \"achievable\", \"relevant\", \"time_bound\", \"clarity\"],\n",
    "            \"rubric\": {\n",
    "                \"specific\":   \"Clearly states the behavior/target (who/what/when/where).\",\n",
    "                \"measurable\": \"Includes a quantifiable criterion (count, frequency, value).\",\n",
    "                \"achievable\": \"Feasible for the patient (resources/constraints).\",\n",
    "                \"relevant\":   \"Aligned to diabetes/health needs in the notes.\",\n",
    "                \"time_bound\": \"Contains a concrete timeframe or deadline.\",\n",
    "                \"clarity\":    \"Readable, unambiguous, free of contradictions.\"\n",
    "            },\n",
    "            \"cases\": cases\n",
    "        }\n",
    "\n",
    "    # Fallback: nothing to evaluate\n",
    "    return {\n",
    "        \"evaluation_type\": \"none\",\n",
    "        \"metrics\": [],\n",
    "        \"rubric\": {},\n",
    "        \"cases\": []\n",
    "    }\n",
    "\n",
    "# ---------- Evaluator Agent (general, plan-driven) ----------\n",
    "EVALUATOR_PROMPT = \"\"\"\n",
    "You are an Evaluator (LLM-as-Judge) that supports multiple evaluation modes via a plan.\n",
    "\n",
    "You will be given a plan from the tool build_eval_plan(limit) with:\n",
    "- evaluation_type: \"engagement_vs_clinician\" or \"smart_goals_rubric\"\n",
    "- metrics: list of metric names to score in [0.0, 1.0]\n",
    "- rubric: guidance for scoring\n",
    "- cases: a list of cases to evaluate\n",
    "\n",
    "CALLS:\n",
    "1) Call build_eval_plan(limit) EXACTLY ONCE (use the user-provided {\"limit\":N} if present; otherwise none).\n",
    "\n",
    "SCORING:\n",
    "- For \"engagement_vs_clinician\":\n",
    "  Each case has:\n",
    "    { case_id, timestamp, device_id, analyzer{category_recommended, rationale}, clinician{category_recommended, rationale} }\n",
    "  Score metrics: correctness, completeness, helpfulness, coherence, relevance.\n",
    "  Also produce:\n",
    "    agreement = \"match\" | \"partial\" | \"mismatch\"\n",
    "  Rules:\n",
    "    - match if categories are the same (case-insensitive).\n",
    "    - partial if different but analyzer rationale substantially overlaps clinician intent.\n",
    "    - mismatch otherwise.\n",
    "\n",
    "- For \"smart_goals_rubric\":\n",
    "  Each case has:\n",
    "    { case_id, timestamp, goal_number, goal_text }\n",
    "  Score metrics: specific, measurable, achievable, relevant, time_bound, clarity.\n",
    "  Focus only on the goal_text vs rubric. If unsafe, note it briefly.\n",
    "\n",
    "OUTPUT: STRICT JSON ONLY:\n",
    "{\n",
    "  \"evaluation_type\": \"string\",\n",
    "  \"cases_scored\": 0,\n",
    "  \"scores\": [\n",
    "    {\n",
    "      \"case_id\": \"string\",\n",
    "      \"metric_scores\": { \"<metric>\": 0.0 },\n",
    "      \"agreement\": \"match|partial|mismatch|n/a\",\n",
    "      \"notes\": \"short justification (<=40 words)\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "PROCESS:\n",
    "- Produce one score object per case with values in [0.0, 1.0].\n",
    "- Use \"agreement\":\"n/a\" for smart_goals_rubric (no clinician).\n",
    "- Keep notes concise and specific.\n",
    "\"\"\"\n",
    "\n",
    "evaluator_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=EVALUATOR_PROMPT,\n",
    "    tools=[build_eval_plan],  # single entry tool that returns everything needed\n",
    ")\n",
    "\n",
    "# ---------- Runner (single call) ----------\n",
    "def run_evaluator(limit: int | None = None, print_json: bool = True):\n",
    "    payload = {\"limit\": limit} if limit else {}\n",
    "    raw = evaluator_agent(json.dumps(payload))\n",
    "    out = _coerce_json(raw)\n",
    "\n",
    "    # Compute overall means dynamically across whatever metric set came back\n",
    "    metrics = set()\n",
    "    for s in out.get(\"scores\", []):\n",
    "        for k in (s.get(\"metric_scores\") or {}).keys():\n",
    "            metrics.add(k)\n",
    "    metrics = sorted(metrics)\n",
    "\n",
    "    buckets = {k: [] for k in metrics}\n",
    "    for s in out.get(\"scores\", []):\n",
    "        for k in metrics:\n",
    "            v = (s.get(\"metric_scores\") or {}).get(k)\n",
    "            if isinstance(v, (int, float)):\n",
    "                buckets[k].append(float(v))\n",
    "\n",
    "    overall = {k: (round(mean(buckets[k]), 4) if buckets[k] else 0.0) for k in metrics}\n",
    "    out[\"cases_scored\"] = len(out.get(\"scores\", []))\n",
    "    out[\"overall\"] = overall\n",
    "\n",
    "    _append_jsonl(EVAL_JSONL, {\n",
    "        \"run_id\": str(uuid.uuid4()),\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "        \"evaluator_output\": out\n",
    "    })\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---- run ----\n",
    "run_evaluator()           # evaluate all available cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf2bbf-daf6-4c02-bc01-a8652dbd6796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182976c4-4a29-415a-9242-f56d905a3a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375f780-a374-40b7-abd4-7d0bbf4054fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
